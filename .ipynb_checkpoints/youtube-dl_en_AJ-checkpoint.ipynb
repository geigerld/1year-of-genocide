{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries\n",
    "First, you need to install the necessary Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yt-dlp pytube pandas webvtt-py requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import webvtt\n",
    "from pytube import Playlist\n",
    "import yt_dlp\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "# Assume `playlist` is a pytube Playlist object already initialized\n",
    "playlist_url = 'https://www.youtube.com/playlist?list=PLzGHKb8i9vTzyS_2FoMDKH9Kg0DOJB-OE'\n",
    "playlist = Playlist(playlist_url)\n",
    "\n",
    "# Get all video URLs in the playlist\n",
    "video_urls = [video.watch_url for video in playlist.videos]\n",
    "\n",
    "# Directory to save thumbnails and transcripts\n",
    "output_dir = 'data/en_AJ'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"\n",
    "    Sanitize the filename by removing invalid characters, full-width symbols,\n",
    "    stripping newlines, and normalizing unicode to ASCII where possible.\n",
    "    \"\"\"\n",
    "    # Normalize full-width characters to their ASCII equivalents\n",
    "    name = unicodedata.normalize('NFKC', name)  # Normalize Unicode characters to ASCII-compatible form\n",
    "    \n",
    "    # Remove problematic characters for filenames\n",
    "    name = re.sub(r'[\\\\/*?:\"<>|]', \"\", name)  # Remove invalid characters\n",
    "    name = name.replace('\\n', '').replace('\\r', '')  # Remove newlines\n",
    "    name = name.strip()  # Trim leading/trailing spaces\n",
    "\n",
    "    # Ensure the filename length is not too long (you can set a specific limit)\n",
    "    max_filename_length = 255\n",
    "    return name[:max_filename_length]\n",
    "\n",
    "def download_thumbnail(thumbnail_url, title):\n",
    "    try:\n",
    "        response = requests.get(thumbnail_url)\n",
    "        sanitized_title = sanitize_filename(title)\n",
    "        thumbnail_file = os.path.join(output_dir, f'{sanitized_title}.jpg')\n",
    "        with open(thumbnail_file, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        return thumbnail_file\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download thumbnail for {title}: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_subtitles(video_url, video_title, subtitle_languages):\n",
    "    sanitized_title = sanitize_filename(video_title)\n",
    "    \n",
    "    # Define the download options\n",
    "    ydl_opts = {\n",
    "        'writesubtitles': True,\n",
    "        'writeautomaticsub': True,\n",
    "        'skip_download': True,  # Skip video download\n",
    "        'outtmpl': os.path.join(output_dir, f'{sanitized_title}.%(ext)s'),  # Use sanitized title\n",
    "        'restrictfilenames': True,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            if 'en' in subtitle_languages:\n",
    "                # Download English subtitles\n",
    "                subtitle_file = os.path.join(output_dir, f'{sanitized_title}.en.vtt')\n",
    "                if not os.path.exists(subtitle_file):\n",
    "                    ydl_opts['subtitleslangs'] = ['en']\n",
    "                    ydl.download([video_url])  # Download subtitles for the video\n",
    "                return subtitle_file\n",
    "            elif subtitle_languages:\n",
    "                # Download the first available subtitle if English is not found\n",
    "                first_lang = list(subtitle_languages)[0]\n",
    "                subtitle_file = os.path.join(output_dir, f'{sanitized_title}.{first_lang}.vtt')\n",
    "                if not os.path.exists(subtitle_file):\n",
    "                    ydl_opts['subtitleslangs'] = [first_lang]\n",
    "                    ydl.download([video_url])\n",
    "                return subtitle_file\n",
    "                \n",
    "    except yt_dlp.utils.DownloadError as e:\n",
    "        error_message = str(e)\n",
    "        print(f\"Error downloading subtitles for {video_title}: {error_message}\")\n",
    "        return None\n",
    "                \n",
    "def download_video_info(video_url, max_retries=3, retry_interval=180):\n",
    "    ydl_opts = {\n",
    "        'writesubtitles': True,\n",
    "        'writeautomaticsub': True,\n",
    "        'skip_download': True,\n",
    "        #'outtmpl': os.path.join(output_dir, f'{\"%(sanitized_title)s\"}.%(ext)s'),\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegMetadata',\n",
    "        }],\n",
    "    }\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                info_dict = ydl.extract_info(video_url, download=False)\n",
    "                video_title = info_dict.get('title', None)\n",
    "                video_id = info_dict.get('id', None)\n",
    "                thumbnail_url = info_dict.get('thumbnail', None)\n",
    "                publish_date = info_dict.get('upload_date', None)  # Format: 'YYYYMMDD'\n",
    "                subtitle_languages = info_dict.get('automatic_captions', {}).keys()\n",
    "\n",
    "                # Download thumbnail\n",
    "                thumbnail_file = None\n",
    "                if thumbnail_url:\n",
    "                    thumbnail_file = download_thumbnail(thumbnail_url, video_title)\n",
    "\n",
    "                # Download subtitles\n",
    "                subtitle_file = None\n",
    "                subtitle_file = download_subtitles(video_url, video_title, subtitle_languages)\n",
    "                \n",
    "            # Return the collected video information\n",
    "            return video_id, video_title, thumbnail_file, subtitle_file, publish_date\n",
    "\n",
    "        except yt_dlp.utils.DownloadError as e:\n",
    "            error_message = str(e)\n",
    "            if \"Sign in to confirm youâ€™re not a bot\" in error_message:\n",
    "                retries += 1\n",
    "                print(f\"Error: {error_message}. Retrying in {retry_interval} seconds... (Attempt {retries}/{max_retries})\")\n",
    "                time.sleep(retry_interval)  # Wait before retrying\n",
    "            else:\n",
    "                print(f\"Failed to download video info for {video_url}: {e}\")\n",
    "                return None, None, None, None, None\n",
    "\n",
    "    # After max retries, log the failure and return None\n",
    "    print(f\"Max retries reached. Skipping video: {video_url}\")\n",
    "    return None, None, None, None, None\n",
    "\n",
    "def vtt_to_text(vtt_file_path):\n",
    "    try:\n",
    "        text = ''\n",
    "        lines = []\n",
    "        deduplicated_lines = []\n",
    "        for caption in webvtt.read(vtt_file_path):\n",
    "            # Split the block into lines and deduplicate them within the block\n",
    "            lines.extend(caption.text.strip().split('\\n'))\n",
    "            #print(caption.text.strip().split('\\n'))\n",
    "        for line in lines:\n",
    "            if line and (not deduplicated_lines or line != deduplicated_lines[-1]):  # Avoid consecutive duplicates\n",
    "                deduplicated_lines.append(line)\n",
    "     \n",
    "        text = \"\\n\".join(deduplicated_lines)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {vtt_file_path} to text: {e}\")\n",
    "        \n",
    "    return text\n",
    "\n",
    "# Create a list to store video information\n",
    "data = []\n",
    "\n",
    "# Loop through each video URL and download the required data\n",
    "for video_url in video_urls:\n",
    "    video_id, video_title, thumbnail_file, subtitle_file, publish_date = download_video_info(video_url)\n",
    "    # If video info is successfully retrieved\n",
    "    if video_id and video_title:\n",
    "        # Convert subtitles to text if available\n",
    "        transcript = None\n",
    "        if subtitle_file and os.path.exists(subtitle_file):\n",
    "            transcript = vtt_to_text(subtitle_file)\n",
    "        else:\n",
    "            print(\"subtitle file not found\")\n",
    "        # Append data to the list\n",
    "        data.append({\n",
    "            'video_id': video_id,\n",
    "            'video_title': video_title,\n",
    "            'thumbnail_path': thumbnail_file,\n",
    "            'transcript': transcript,\n",
    "            'publish_date': publish_date\n",
    "        })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['video_id', 'video_title', 'thumbnail_path', 'transcript', 'publish_date'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(os.path.join(output_dir,\"../\", 'en_AJ.csv'), index=False)\n",
    "\n",
    "print(f\"Dataset created successfully with {len(df)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
